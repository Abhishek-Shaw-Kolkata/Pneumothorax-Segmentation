{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# The below two functions have been given by organizers in the data section in mask_functions.py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datetime import datetime,timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import import_ipynb\n",
    "from config import IMG_WIDTH,IMG_HEIGHT,N_CHANNELS,BATCH_SIZE,N_CLASS,NB_EPOCH \n",
    "from keras.losses import BinaryCrossentropy,binary_crossentropy\n",
    "def mask2rle(img, width, height):\n",
    "    '''\n",
    "        Converts image of size width x height to RLE encoded form \n",
    "        Args:\n",
    "            img : Image array\n",
    "            width : width of image\n",
    "            height : height of image\n",
    "        Returns:\n",
    "            encoded RLE String\n",
    "    '''\n",
    "    rle = []\n",
    "    lastColor = 0;\n",
    "    currentPixel = 0;\n",
    "    runStart = -1;\n",
    "    runLength = 0;\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            currentColor = img[x][y]\n",
    "            if currentColor != lastColor:\n",
    "                if currentColor == 255:\n",
    "                    runStart = currentPixel;\n",
    "                    runLength = 1;\n",
    "                else:\n",
    "                    rle.append(str(runStart));\n",
    "                    rle.append(str(runLength));\n",
    "                    runStart = -1;\n",
    "                    runLength = 0;\n",
    "                    currentPixel = 0;\n",
    "            elif runStart > -1:\n",
    "                runLength += 1\n",
    "            lastColor = currentColor;\n",
    "            currentPixel+=1;\n",
    "\n",
    "    return \" \".join(rle)\n",
    "\n",
    "def rle2mask(rle, width, height):\n",
    "    '''\n",
    "        Converts RLE encoded pixel to image of size width x height\n",
    "        Example, rle '1 3 10 5' implies pixels 1,2,3 are to be included in the mask, as well as 14,15,16,17,18.\n",
    "        Args:\n",
    "            rle : encoded pixel in RLE form\n",
    "            width : width of image\n",
    "            height : height of image\n",
    "        Returns:\n",
    "            decoded image masks\n",
    "    '''\n",
    "    mask= np.zeros(width* height)\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        current_position += start\n",
    "        mask[current_position:current_position+lengths[index]] = 255\n",
    "        current_position += lengths[index]\n",
    "    \n",
    "    return mask.reshape(width, height)\n",
    "\n",
    "def get_list_of_files(dir_name):\n",
    "    '''\n",
    "        For the given path, get the List of all files in the directory tree \n",
    "        INPUT:\n",
    "            dir_name - path to the directory where files to be searched\n",
    "        OUTPUT:\n",
    "            list containing full path of all files present inside input directory\n",
    "    '''\n",
    "    # names in the given directory \n",
    "    list_of_files = os.listdir(dir_name)\n",
    "    all_files = []\n",
    "    for entry in list_of_files:\n",
    "        full_path = os.path.join(dir_name,entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            all_files = all_files + get_list_of_files(full_path)\n",
    "        else:\n",
    "            all_files.append(full_path)\n",
    "    return all_files\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred,smooth = 1e-5):\n",
    "    '''\n",
    "        Given true and predicted pixel values it calculates dice_coefficient\n",
    "        Args:\n",
    "            y_true : true pixel values\n",
    "            y_pred : predicted pixel values by model\n",
    "            smooth : small value to avoid divide by zero error\n",
    "        Returns:\n",
    "            dice_coefficient value\n",
    "    '''\n",
    "    y_true_f = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    '''\n",
    "        Given true and predicted pixel values it calculates sum of dice loss and binary corss entrpy loss\n",
    "        Args:\n",
    "            y_true : true pixel values\n",
    "            y_pred : predicted pixel values by model\n",
    "            smooth : small value to avoid divide by zero error\n",
    "        Returns:\n",
    "            sum of BCE loss + Dice loss\n",
    "    '''\n",
    "    return 1.0 - dice_coef(y_true, y_pred) + binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "# define custom learning rate schedule\n",
    "class CosineAnnealingLearningRateSchedule(tf.keras.callbacks.Callback):\n",
    "    # constructor\n",
    "    def __init__(self, n_epochs, n_cycles, lrate_max, verbose=0):\n",
    "        self.epochs = n_epochs\n",
    "        self.cycles = n_cycles\n",
    "        self.lr_max = lrate_max\n",
    "        self.lrates = list()\n",
    " \n",
    "    # calculate learning rate for an epoch\n",
    "    def cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max):\n",
    "        epochs_per_cycle = np.floor(n_epochs/n_cycles)\n",
    "        cos_inner = (np.pi * (epoch % epochs_per_cycle)) / (epochs_per_cycle)\n",
    "        return lrate_max/2 * (np.cos(cos_inner) + 1)\n",
    " \n",
    "    # calculate and set learning rate at the start of the epoch\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # calculate learning rate\n",
    "        lr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max)\n",
    "        # set learning rate\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        # log value\n",
    "        self.lrates.append(lr)\n",
    "        \n",
    "def set_log_checkpoint(name):\n",
    "    '''\n",
    "        helper function to set model checkpoint, tensorboard callback\n",
    "        Args:\n",
    "           name: the name of the model\n",
    "        Returns:\n",
    "                model checkpoint callback , tensorboard callback, learningrate schedule callback\n",
    "            \n",
    "    '''\n",
    "    global CHECKPOINT_PATH\n",
    "    CHECKPOINT_PATH = \"training/\" + name + \".ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(CHECKPOINT_PATH)\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT_PATH,\n",
    "                                                    save_weights_only=True,\n",
    "                                                    verbose=1,\n",
    "                                                    monitor='val_loss',\n",
    "                                                    save_best_only=True)\n",
    "    # Load the TensorBoard notebook extension\n",
    "    %load_ext tensorboard\n",
    "    # Clear any logs from previous runs\n",
    "    ! rm -rf ./logs/ \n",
    "    # Set up log directory\n",
    "    logdir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    #print(logdir)\n",
    "    %tensorboard --logdir $logdir\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    ca = CosineAnnealingLearningRateSchedule(NB_EPOCH, 10, 0.01)\n",
    "    # early = keras.callbacks.EarlyStopping(monitor='val_recall', min_delta=0, patience=40, verbose=1, mode='auto')\n",
    "    return cp_callback,tensorboard_callback,ca\n",
    "\n",
    "def plot_metrics(history):\n",
    "    '''\n",
    "        Helper function to plot traing history such as train and validation loss and dice coeffcient \n",
    "        Args:\n",
    "           history: Model training history obejct \n",
    "        Returns:\n",
    "                None\n",
    "            \n",
    "    '''\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for DiceCoef\n",
    "    fig, axes = plt.subplots(1, 2,figsize=(20,7))\n",
    "    axes[0].plot(history.history['dice_coef'])\n",
    "    axes[0].plot(history.history['val_dice_coef'],linestyle=\"--\")\n",
    "    axes[0].set_title('Model epoch vs DiceCoef', fontsize=18, pad=15)\n",
    "    axes[0].set_ylabel('DiceCoef',size=14)\n",
    "    axes[0].set_xlabel('epoch',size=14)\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    #plt.show()\n",
    "    # summarize history for loss\n",
    "    #plt.subplot(122)\n",
    "    axes[1].plot(history.history['loss'])\n",
    "    axes[1].plot(history.history['val_loss'],linestyle=\"--\")\n",
    "    axes[1].set_title('model epoch vs loss', fontsize=18, pad=15)\n",
    "    axes[1].set_ylabel('loss',size=14)\n",
    "    axes[1].set_xlabel('epoch',size=14)\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
