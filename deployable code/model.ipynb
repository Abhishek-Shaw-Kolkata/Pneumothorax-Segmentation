{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "small-county",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from config.ipynb\n",
      "env: SM_FRAMEWORK=tf.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from utils import CosineAnnealingLearningRateSchedule,set_log_checkpoint,plot_metrics,combined_loss,dice_coef\n",
    "from config import IMG_WIDTH,IMG_HEIGHT,N_CHANNELS,BATCH_SIZE,N_CLASS,NB_EPOCH \n",
    "%env SM_FRAMEWORK=tf.keras\n",
    "import segmentation_models as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "img_size = 256\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "def load_data(data):\n",
    "    '''\n",
    "        Extracts Image and mask paths from input DF\n",
    "        Args:\n",
    "            data : DataFrame contains paths\n",
    "        Returns:\n",
    "                images : X-Ray image paths \n",
    "                masks :  X-Ray mask paths\n",
    "    '''\n",
    "    images = data['ImagePath']\n",
    "    masks = data['MaskPath']\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def read_image(datapoint):\n",
    "    '''\n",
    "        Reads images that are stored into disk\n",
    "        Args:\n",
    "            datapoint : Image path\n",
    "        Returns:\n",
    "                image tensor \n",
    "    '''\n",
    "    img = tf.io.read_file(datapoint)\n",
    "    img = tf.image.decode_png(img, channels= N_CHANNELS)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32) \n",
    "    image = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) \n",
    "\n",
    "    image = exposure.equalize_adapthist(image)     # contrast correction\n",
    "    return image\n",
    "\n",
    "def read_mask(datapoint):\n",
    "    '''\n",
    "        Reads masks that are stored into disk\n",
    "        Args:\n",
    "            datapoint : Mask path\n",
    "        Returns:\n",
    "                Mask tensor \n",
    "    '''\n",
    "    label = tf.io.read_file(datapoint)\n",
    "    label = tf.image.decode_png(label, channels= 1)\n",
    "    label = tf.image.convert_image_dtype(label, tf.float32) \n",
    "    mask = tf.image.resize(label, [IMG_WIDTH, IMG_HEIGHT])\n",
    "                           \n",
    "    return mask\n",
    "    \n",
    "def preprocess_train(image, image_mask):\n",
    "    '''\n",
    "        Reads images and masks that are stored into disk and applies appropriate tranformation\n",
    "        Args:\n",
    "            image : Image Tensor\n",
    "            image_mask : mask Tensor\n",
    "        Returns:\n",
    "                Transformed Images and Masks \n",
    "    '''\n",
    "    def f(image, image_mask):\n",
    "\n",
    "        image = image.decode()\n",
    "        image_mask = image_mask.decode()\n",
    "\n",
    "        image = read_image(image)\n",
    "        image_mask = read_mask(image_mask)\n",
    "        \n",
    "        a = tf.random.uniform((),minval=0,maxval=1)\n",
    "        if a<0.2:\n",
    "            image=tf.image.flip_left_right(image)\n",
    "            image_mask=tf.image.flip_left_right(image_mask)\n",
    "        if a<0.4 and a>0.2:\n",
    "            image = tf.image.random_brightness(image, max_delta=0.15) # Random brightness\n",
    "        if a<0.6 and a>0.4:\n",
    "            image=tf.image.adjust_gamma(image, gamma=tf.random.uniform((),minval=0,maxval=1), gain=1)\n",
    "        if a<0.8 and a>0.6:\n",
    "            image=tf.image.random_contrast(image,lower=0.2,upper=0.3)\n",
    "        if a<1.0 and a>0.8:\n",
    "            image=tf.image.random_saturation(image, lower=2, upper=5)\n",
    "            \n",
    "        return image, image_mask\n",
    "    images, masks = tf.numpy_function(f, [image, image_mask], [tf.float32, tf.float32])\n",
    "    images.set_shape([img_size, img_size, 3])\n",
    "    masks.set_shape([img_size, img_size, 1])\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def preprocess_test(image, image_mask):\n",
    "    def f(image, image_mask):\n",
    "\n",
    "        image = image.decode()\n",
    "        image_mask = image_mask.decode()\n",
    "\n",
    "        image = read_image(image)\n",
    "        image_mask = read_mask(image_mask)\n",
    "\n",
    "        return image, image_mask\n",
    "    images, masks = tf.numpy_function(f, [image, image_mask], [tf.float32, tf.float32])\n",
    "    images.set_shape([img_size, img_size, 3])\n",
    "    masks.set_shape([img_size, img_size, 1])\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def tf_dataset(x, y, batch=8,type_ = 'train'):\n",
    "    '''\n",
    "        Creates train and test data pipeline that will be used while model training \n",
    "        Args:\n",
    "            x : Image paths\n",
    "            y : Mask paths\n",
    "            batch : batch size to be used\n",
    "            type_ : type of data train or test\n",
    "        Returns:\n",
    "                dataset object \n",
    "            \n",
    "    '''\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.cache().shuffle(buffer_size=15000)\n",
    "    if type_ == 'train':\n",
    "        dataset = dataset.map(preprocess_train,num_parallel_calls=AUTOTUNE)\n",
    "    else:\n",
    "        dataset = dataset.map(preprocess_test,num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_segmentaion_model(name= 'Uefficientnetb4', BACKBONE = 'efficientnetb4',ENCODER_WEIGHTS = 'imagenet'):\n",
    "    '''\n",
    "        Creates segmentaion model object and compiles it with Adam optimizer and combined_loss function\n",
    "        Args:\n",
    "            name : Name of model \n",
    "            BACKBONE : BACKBONE model name to be used as encider part\n",
    "            ENCODER_WEIGHTS : weights with which to assign the encoder\n",
    "        Returns:\n",
    "                complied segmentaion model object \n",
    "            \n",
    "    '''\n",
    "    tf.random.set_seed(100) # Set global seed\n",
    "    keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "    model_seg = sm.Unet(BACKBONE,  input_shape=(256, 256, 3), encoder_weights= ENCODER_WEIGHTS)\n",
    "    #keras.utils.plot_model(model_seg, name + \".png\", show_shapes=True)\n",
    "\n",
    "    model_seg.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss=combined_loss , metrics=[dice_coef])\n",
    "\n",
    "    return model_seg\n",
    "\n",
    "def train_and_plot_metrics(model,name,cp_callback,tensorboard_callback,train_dataset,test_dataset):\n",
    "    '''\n",
    "        Trains model on train data and plots different training metrics\n",
    "        Args:\n",
    "            model : Model object to which to feed the data \n",
    "            cp_callback : Model checkpoint callback object\n",
    "            tensorboard_callback : tensorboard callback obejct \n",
    "            train_dataset : train_dataset obejct\n",
    "            test_dataset: test_dataset obejct \n",
    "        Returns:\n",
    "                None\n",
    "            \n",
    "    '''\n",
    "    history = model.fit(train_dataset,                           \n",
    "                            use_multiprocessing=True,\n",
    "                            epochs=NB_EPOCH,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            steps_per_epoch = len(train_dataset),\n",
    "                            validation_data= test_dataset,\n",
    "                            verbose=1,\n",
    "                            callbacks=[cp_callback, tensorboard_callback ]\n",
    "                        )\n",
    "    \n",
    "    # Loading best saved model\n",
    "    model.load_weights(CHECKPOINT_PATH)\n",
    "    # saving training history \n",
    "    np.save('./training/' + name + '.npy',history.history)\n",
    "    #saving model with architecture\n",
    "    model.save('./models/' + name)\n",
    "    plot_metrics(history)\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    df_meta_final = pd.read_pickle('./df_meta_final.pkl')\n",
    "    df_meta_final['class_'] = df_meta_final['class_'].map({'Pneumothorax' :1 ,'NotPneumothorax' : 0})\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_meta_final, df_meta_final['class_'],stratify =df_meta_final['class_'],  test_size=0.20, random_state=42)\n",
    "    \n",
    "    images, masks = load_data(X_train)\n",
    "    train_dataset = tf_dataset(images, masks,BATCH_SIZE )\n",
    "\n",
    "    images, masks = load_data(X_test)\n",
    "    test_dataset = tf_dataset(images, masks, BATCH_SIZE,type_='test')\n",
    "    \n",
    "    name= 'Uefficientnetb4' \n",
    "    model_seg = get_segmentaion_model(name, BACKBONE = 'efficientnetb4')\n",
    "    cp_callback,tensorboard_callback,ca = set_log_checkpoint(name)\n",
    "    train_and_plot_metrics(model_seg,name,cp_callback,tensorboard_callback,train_dataset,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "finnish-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
